import FirecrawlApp from '@mendable/firecrawl-js';
import type { 
  VulnerabilityScanner, 
  VulnerabilityIntelligence, 
  GitHubAdvisory, 
  OSVQuery, 
  OSVResponse,
  PackageInfo 
} from '../types/data-pipeline.js';
import { DATA_PIPELINE_CONFIG } from '../config/data-pipeline.js';
import { logger } from '../utils/logger.js';

export class VulnerabilityIntelligenceScanner implements VulnerabilityScanner {
  private firecrawl?: FirecrawlApp;
  private creditsUsed: number = 0;
  private lastScanTime: Date = new Date();

  constructor() {
    const apiKey = DATA_PIPELINE_CONFIG.firecrawl.apiKey;
    if (apiKey && apiKey !== 'fc-your-api-key-here') {
      this.firecrawl = new FirecrawlApp({ apiKey });
      logger.info('üî• Firecrawl initialized for vulnerability intelligence');
    } else {
      logger.warn('‚ö†Ô∏è  Firecrawl API key not configured - GitHub advisory scraping disabled');
    }
  }

  /**
   * Scan GitHub Security Advisories using Firecrawl
   */
  async scanGitHubAdvisories(ecosystems: string[] = ['npm', 'pip', 'maven']): Promise<GitHubAdvisory[]> {
    if (!this.firecrawl) {
      logger.warn('Firecrawl not configured, skipping GitHub advisories');
      return [];
    }

    const advisories: GitHubAdvisory[] = [];
    const maxCredits = DATA_PIPELINE_CONFIG.firecrawl.maxCreditsPerScan;

    try {
      for (const ecosystem of ecosystems) {
        if (this.creditsUsed >= maxCredits) {
          logger.warn(`‚ö†Ô∏è  Firecrawl credit limit reached (${maxCredits}), stopping GitHub scan`);
          break;
        }

        logger.info(`üîç Scanning GitHub advisories for ${ecosystem}...`);
        
        // Focus on high/critical severity for efficiency
        const url = `${DATA_PIPELINE_CONFIG.sources.github.baseUrl}?query=ecosystem:${ecosystem}+severity:high,critical`;
        
        const result = await this.firecrawl.scrapeUrl(url, {
          formats: ['markdown'],
          onlyMainContent: true
        });

        this.creditsUsed += 1;

        if (result.success && result.data?.markdown) {
          // Parse markdown content for advisories (simplified)
          const parsed = this.parseGitHubMarkdown(result.data.markdown, ecosystem);
          advisories.push(...parsed);
          logger.info(`‚úÖ Found ${parsed.length} advisories for ${ecosystem}`);
        }

        // Rate limiting
        await this.delay(DATA_PIPELINE_CONFIG.firecrawl.rateLimitDelay);
      }

      logger.info(`üéØ GitHub scan complete: ${advisories.length} advisories, ${this.creditsUsed} credits used`);
      return advisories;

    } catch (error) {
      logger.error('‚ùå GitHub advisory scanning failed:', error);
      return advisories; // Return partial results
    }
  }

  /**
   * Query OSV.dev database for comprehensive vulnerability data
   */
  async queryOSVDatabase(packages: PackageInfo[]): Promise<OSVResponse> {
    logger.info(`üîç Querying OSV.dev for ${packages.length} packages...`);
    
    const allVulns: OSVResponse['vulns'] = [];
    const batchSize = DATA_PIPELINE_CONFIG.sources.osv.batchSize;

    try {
      // Process packages in batches
      for (let i = 0; i < packages.length; i += batchSize) {
        const batch = packages.slice(i, i + batchSize);
        
        for (const pkg of batch) {
          const query: OSVQuery = {
            package: {
              name: pkg.name,
              ecosystem: pkg.ecosystem
            }
          };

          const response = await fetch(`${DATA_PIPELINE_CONFIG.sources.osv.baseUrl}/query`, {
            method: 'POST',
            headers: {
              'Content-Type': 'application/json',
            },
            body: JSON.stringify(query)
          });

          if (response.ok) {
            const data = await response.json() as OSVResponse;
            if (data.vulns && data.vulns.length > 0) {
              allVulns.push(...data.vulns);
              logger.debug(`Found ${data.vulns.length} vulnerabilities for ${pkg.name}`);
            }
          }

          // Rate limiting for OSV.dev
          await this.delay(100);
        }
      }

      logger.info(`‚úÖ OSV.dev scan complete: ${allVulns.length} vulnerabilities found`);
      return { vulns: allVulns };

    } catch (error) {
      logger.error('‚ùå OSV.dev query failed:', error);
      return { vulns: [] };
    }
  }

  /**
   * Detect potential zero-day vulnerabilities
   */
  async detectZeroDayVulnerabilities(): Promise<VulnerabilityIntelligence[]> {
    if (!DATA_PIPELINE_CONFIG.scanning.enableZeroDayMonitoring) {
      return [];
    }

    logger.info('üö® Scanning for zero-day vulnerabilities...');
    
    const zeroDays: VulnerabilityIntelligence[] = [];
    const cutoffDate = new Date();
    cutoffDate.setHours(cutoffDate.getHours() - DATA_PIPELINE_CONFIG.analysis.zerodayAgeHours);

    try {
      // Scan recent GitHub advisories for zero-day patterns
      const recentAdvisories = await this.scanGitHubAdvisories(['npm', 'pip']);
      
      for (const advisory of recentAdvisories) {
        const publishedDate = new Date(advisory.published_at);
        
        // Check if it's recent and high severity
        if (publishedDate > cutoffDate && 
            ['critical', 'high'].includes(advisory.severity.toLowerCase())) {
          
          const intelligence: VulnerabilityIntelligence = {
            id: advisory.cve_id || advisory.ghsa_id,
            packageName: advisory.package.name,
            ecosystem: advisory.package.ecosystem,
            severity: advisory.severity.toLowerCase() as any,
            cvssScore: advisory.cvss_score,
            affectedVersions: advisory.vulnerable_version_range,
            fixedVersions: advisory.patched_versions,
            description: advisory.description,
            references: advisory.references,
            source: 'github-firecrawl',
            discoveredAt: new Date().toISOString(),
            isZeroDay: true,
            exploitAvailable: this.detectExploitKeywords(advisory.description),
          };

          zeroDays.push(intelligence);
        }
      }

      logger.info(`üéØ Zero-day detection complete: ${zeroDays.length} potential zero-days found`);
      return zeroDays;

    } catch (error) {
      logger.error('‚ùå Zero-day detection failed:', error);
      return [];
    }
  }

  /**
   * Comprehensive scan of all vulnerability sources
   */
  async scanAllSources(): Promise<VulnerabilityIntelligence[]> {
    logger.info('üöÄ Starting comprehensive vulnerability scan...');
    const startTime = Date.now();
    
    const allVulnerabilities: VulnerabilityIntelligence[] = [];

    try {
      // 1. Scan GitHub advisories
      const githubAdvisories = await this.scanGitHubAdvisories();
      const githubIntel = githubAdvisories.map(this.convertGitHubToIntelligence);
      allVulnerabilities.push(...githubIntel);

      // 2. Detect zero-days
      const zeroDays = await this.detectZeroDayVulnerabilities();
      allVulnerabilities.push(...zeroDays);

      // 3. Deduplicate by vulnerability ID
      const deduped = this.deduplicateVulnerabilities(allVulnerabilities);

      const endTime = Date.now();
      logger.info(`‚úÖ Comprehensive scan complete: ${deduped.length} unique vulnerabilities found in ${endTime - startTime}ms`);
      
      this.lastScanTime = new Date();
      return deduped;

    } catch (error) {
      logger.error('‚ùå Comprehensive vulnerability scan failed:', error);
      return allVulnerabilities; // Return partial results
    }
  }

  /**
   * Parse GitHub advisory data into structured format
   */
  private parseGitHubAdvisories(rawData: any[], ecosystem: string): GitHubAdvisory[] {
    return rawData.map(item => ({
      id: item.id || item.ghsa_id,
      ghsa_id: item.ghsa_id,
      cve_id: item.cve_id,
      title: item.title,
      description: item.description,
      severity: item.severity || 'medium',
      cvss_score: item.cvss_score,
      published_at: item.published_at || new Date().toISOString(),
      updated_at: item.updated_at || new Date().toISOString(),
      package: {
        name: item.package_name,
        ecosystem: ecosystem
      },
      vulnerable_version_range: item.vulnerable_versions || '<999.0.0',
      patched_versions: item.patched_versions || '>=999.0.0',
      references: Array.isArray(item.references) ? item.references : []
    }));
  }

  /**
   * Parse GitHub markdown content for advisories (simplified implementation)
   */
  private parseGitHubMarkdown(markdown: string, ecosystem: string): GitHubAdvisory[] {
    // This is a simplified parser for demo purposes
    // In production, you'd want more sophisticated parsing
    const advisories: GitHubAdvisory[] = [];
    
    // Look for common patterns in GitHub advisory markdown
    const lines = markdown.split('\n');
    let currentAdvisory: Partial<GitHubAdvisory> = {};
    
    for (const line of lines) {
      if (line.includes('GHSA-') || line.includes('CVE-')) {
        // Start of new advisory
        if (currentAdvisory.id) {
          advisories.push(this.completeAdvisory(currentAdvisory, ecosystem));
        }
        currentAdvisory = {
          id: this.extractId(line),
          ghsa_id: this.extractGHSA(line),
          cve_id: this.extractCVE(line)
        };
      } else if (line.toLowerCase().includes('severity')) {
        currentAdvisory.severity = this.extractSeverity(line);
      } else if (line.toLowerCase().includes('package')) {
        const packageName = this.extractPackageName(line);
        if (packageName) {
          currentAdvisory.package = { name: packageName, ecosystem };
        }
      }
    }
    
    // Add the last advisory
    if (currentAdvisory.id) {
      advisories.push(this.completeAdvisory(currentAdvisory, ecosystem));
    }
    
    return advisories;
  }

  /**
   * Complete advisory with default values
   */
  private completeAdvisory(partial: Partial<GitHubAdvisory>, ecosystem: string): GitHubAdvisory {
    return {
      id: partial.id || 'unknown',
      ghsa_id: partial.ghsa_id || 'unknown',
      cve_id: partial.cve_id,
      title: partial.title || 'Security Advisory',
      description: partial.description || 'Security vulnerability detected',
      severity: partial.severity || 'medium',
      cvss_score: partial.cvss_score,
      published_at: partial.published_at || new Date().toISOString(),
      updated_at: partial.updated_at || new Date().toISOString(),
      package: partial.package || { name: 'unknown', ecosystem },
      vulnerable_version_range: partial.vulnerable_version_range || '<999.0.0',
      patched_versions: partial.patched_versions || '>=999.0.0',
      references: partial.references || []
    };
  }

  /**
   * Extract ID from line
   */
  private extractId(line: string): string {
    const ghsaMatch = line.match(/GHSA-[a-z0-9-]+/i);
    const cveMatch = line.match(/CVE-\d{4}-\d+/i);
    return ghsaMatch?.[0] || cveMatch?.[0] || 'unknown';
  }

  /**
   * Extract GHSA ID from line
   */
  private extractGHSA(line: string): string {
    const match = line.match(/GHSA-[a-z0-9-]+/i);
    return match?.[0] || 'unknown';
  }

  /**
   * Extract CVE ID from line
   */
  private extractCVE(line: string): string | undefined {
    const match = line.match(/CVE-\d{4}-\d+/i);
    return match?.[0];
  }

  /**
   * Extract severity from line
   */
  private extractSeverity(line: string): string {
    const severities = ['critical', 'high', 'medium', 'low'];
    for (const severity of severities) {
      if (line.toLowerCase().includes(severity)) {
        return severity;
      }
    }
    return 'medium';
  }

  /**
   * Extract package name from line
   */
  private extractPackageName(line: string): string | undefined {
    // Simple extraction - look for common package name patterns
    const patterns = [
      /package[:\s]+([a-z0-9-_]+)/i,
      /npm[:\s]+([a-z0-9-_]+)/i,
      /`([a-z0-9-_]+)`/i
    ];
    
    for (const pattern of patterns) {
      const match = line.match(pattern);
      if (match) {
        return match[1];
      }
    }
    
    return undefined;
  }

  /**
   * Convert GitHub advisory to vulnerability intelligence format
   */
  private convertGitHubToIntelligence = (advisory: GitHubAdvisory): VulnerabilityIntelligence => ({
    id: advisory.cve_id || advisory.ghsa_id,
    packageName: advisory.package.name,
    ecosystem: advisory.package.ecosystem,
    severity: advisory.severity.toLowerCase() as any,
    cvssScore: advisory.cvss_score,
    affectedVersions: advisory.vulnerable_version_range,
    fixedVersions: advisory.patched_versions,
    description: advisory.description,
    references: advisory.references,
    source: 'github-firecrawl',
    discoveredAt: new Date().toISOString(),
    isZeroDay: this.isRecentVulnerability(advisory.published_at),
    exploitAvailable: this.detectExploitKeywords(advisory.description),
  });

  /**
   * Detect exploit-related keywords in vulnerability descriptions
   */
  private detectExploitKeywords(description: string): boolean {
    const exploitKeywords = [
      'exploit', 'poc', 'proof of concept', 'weaponized', 
      'in the wild', 'active exploitation', 'zero-day'
    ];
    
    const lowerDesc = description.toLowerCase();
    return exploitKeywords.some(keyword => lowerDesc.includes(keyword));
  }

  /**
   * Check if vulnerability is recent (potential zero-day)
   */
  private isRecentVulnerability(publishedAt: string): boolean {
    const published = new Date(publishedAt);
    const cutoff = new Date();
    cutoff.setHours(cutoff.getHours() - DATA_PIPELINE_CONFIG.analysis.zerodayAgeHours);
    return published > cutoff;
  }

  /**
   * Remove duplicate vulnerabilities by ID
   */
  private deduplicateVulnerabilities(vulnerabilities: VulnerabilityIntelligence[]): VulnerabilityIntelligence[] {
    const seen = new Set<string>();
    return vulnerabilities.filter(vuln => {
      if (seen.has(vuln.id)) {
        return false;
      }
      seen.add(vuln.id);
      return true;
    });
  }

  /**
   * Rate limiting delay
   */
  private delay(ms: number): Promise<void> {
    return new Promise(resolve => setTimeout(resolve, ms));
  }

  /**
   * Get scanning statistics
   */
  getStats() {
    return {
      creditsUsed: this.creditsUsed,
      lastScanTime: this.lastScanTime,
      maxCredits: DATA_PIPELINE_CONFIG.firecrawl.maxCreditsPerScan
    };
  }

  /**
   * Reset credit counter (for testing or new billing cycle)
   */
  resetCredits() {
    this.creditsUsed = 0;
    logger.info('üîÑ Firecrawl credits reset');
  }
}